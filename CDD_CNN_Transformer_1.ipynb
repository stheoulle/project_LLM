{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìì Notebook : Classification multimodale du cancer du sein avec CNN + Transformer\n",
    "\n",
    "# üì¶ Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Concatenate, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import json\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üìÅ Dossiers\n",
    "image_dir_le = 'CDD-CESM/PKG - CDD-CESM/CDD-CESM/Low energy images of CDD-CESM'\n",
    "image_dir_sub = 'CDD-CESM/PKG - CDD-CESM/CDD-CESM/Subtracted images of CDD-CESM'\n",
    "json_dir = 'CDD-CESM/json_output'\n",
    "excel_path = 'processed_metadata.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üîÑ Chargement des images (8 vues par patient)\n",
    "def load_image_stack(patient_id):\n",
    "    paths = [\n",
    "        f\"{image_dir_le}/P{patient_id}_L_DM_CC.jpg\",\n",
    "        f\"{image_dir_le}/P{patient_id}_L_DM_MLO.jpg\",\n",
    "        f\"{image_dir_sub}/P{patient_id}_L_CM_CC.jpg\",\n",
    "        f\"{image_dir_sub}/P{patient_id}_L_CM_MLO.jpg\",\n",
    "        f\"{image_dir_le}/P{patient_id}_R_DM_CC.jpg\",\n",
    "        f\"{image_dir_le}/P{patient_id}_R_DM_MLO.jpg\",\n",
    "        f\"{image_dir_sub}/P{patient_id}_R_CM_CC.jpg\",\n",
    "        f\"{image_dir_sub}/P{patient_id}_R_CM_MLO.jpg\",\n",
    "    ]\n",
    "    imgs = [np.array(Image.open(p).convert('L').resize((224, 224))) for p in paths]\n",
    "    stack = np.stack(imgs, axis=-1)\n",
    "    return stack / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üî¢ Chargement des m√©tadonn√©es\n",
    "meta_df = pd.read_csv(excel_path)\n",
    "meta_df = meta_df.dropna(subset=['Patient_ID', 'Pathology Classification/ Follow up'])\n",
    "meta_df['Patient_ID'] = meta_df['Patient_ID'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Textes JSON\n",
    "texts = []\n",
    "for pid in meta_df['Patient_ID']:\n",
    "    path = os.path.join(json_dir, f\"P{pid}.json\")\n",
    "    if os.path.exists(path):\n",
    "        with open(path, encoding=\"utf-8\") as f:\n",
    "            try:\n",
    "                d = json.load(f)\n",
    "                flat_text = []\n",
    "                for v in d.values():\n",
    "                    flat_text.extend(map(str, v) if isinstance(v, list) else [str(v)])\n",
    "                texts.append(\" \".join(flat_text))\n",
    "            except:\n",
    "                texts.append(\"\")\n",
    "    else:\n",
    "        texts.append(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Echantillonnage 80%\n",
    "sampled_df = meta_df.sample(frac=0.8, random_state=42)\n",
    "sampled_patient_ids = sampled_df['Patient_ID'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Images valides\n",
    "images = []\n",
    "valid_labels = []\n",
    "valid_pids = []\n",
    "skipped_image = 0\n",
    "\n",
    "for pid, label in zip(sampled_df['Patient_ID'], sampled_df['Pathology Classification/ Follow up']):\n",
    "    try:\n",
    "        img = load_image_stack(pid)\n",
    "        images.append(img)\n",
    "        valid_labels.append(label)\n",
    "        valid_pids.append(pid)\n",
    "    except:\n",
    "        skipped_image += 1\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Alignement des donn√©es\n",
    "image_patient_ids = set(valid_pids)\n",
    "text_patient_ids = set(sampled_patient_ids)\n",
    "metadata_patient_ids = set(meta_df['Patient_ID'])\n",
    "common_patient_ids = list(image_patient_ids & text_patient_ids & metadata_patient_ids)\n",
    "\n",
    "image_dict = {pid: img for pid, img in zip(valid_pids, images) if pid in common_patient_ids}\n",
    "label_dict = {pid: label for pid, label in zip(valid_pids, valid_labels) if pid in common_patient_ids}\n",
    "text_dict = {pid: text for pid, text in zip(sampled_patient_ids, texts) if pid in common_patient_ids}\n",
    "meta_dict = {pid: meta_df[meta_df['Patient_ID'] == pid].iloc[0] for pid in common_patient_ids}\n",
    "\n",
    "images_filtered = np.array([image_dict[pid] for pid in common_patient_ids])\n",
    "labels_filtered = [label_dict[pid] for pid in common_patient_ids]\n",
    "texts_filtered = [text_dict[pid] for pid in common_patient_ids]\n",
    "meta_df_filtered = pd.DataFrame([meta_dict[pid] for pid in common_patient_ids])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Textes vectoris√©s\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "text_features_filtered = vectorizer.fit_transform(texts_filtered).toarray()\n",
    "\n",
    "# --- Encodage des m√©tadonn√©es\n",
    "numerical = meta_df_filtered.select_dtypes(include=['float', 'int']).columns.tolist()\n",
    "categorical = meta_df_filtered.select_dtypes(include=['object']).drop(columns=['Patient_ID', 'Pathology Classification/ Follow up']).columns.tolist()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "meta_num_filtered = scaler.fit_transform(meta_df_filtered[numerical])\n",
    "meta_cat_filtered = encoder.fit_transform(meta_df_filtered[categorical])\n",
    "meta_features_filtered = np.concatenate([meta_num_filtered, meta_cat_filtered], axis=1)\n",
    "\n",
    "# --- Encodage des labels\n",
    "valid_labels_encoded, label_names = pd.factorize(labels_filtered)\n",
    "labels_cat = to_categorical(valid_labels_encoded)\n",
    "\n",
    "# --- Poids de classes\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(valid_labels_encoded), y=valid_labels_encoded)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Split train/test\n",
    "X_img_temp, X_img_test, X_meta_temp, X_meta_test, X_txt_temp, X_txt_test, y_temp, y_test = train_test_split(\n",
    "    images_filtered, meta_features_filtered, text_features_filtered, labels_cat,\n",
    "    test_size=0.1, random_state=42)\n",
    "\n",
    "X_img_train, X_img_val, X_meta_train, X_meta_val, X_txt_train, X_txt_val, y_train, y_val = train_test_split(\n",
    "    X_img_temp, X_meta_temp, X_txt_temp, y_temp,\n",
    "    test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üîß Transformer block\n",
    "from tensorflow.keras.layers import LayerNormalization, MultiHeadAttention, Layer\n",
    "\n",
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            Dense(ff_dim, activation=\"relu\"),\n",
    "            Dense(embed_dim)\n",
    "        ])\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üß† Mod√®le multimodal CNN + Transformer\n",
    "img_input = Input(shape=(224, 224, 8))\n",
    "meta_input = Input(shape=(meta_features_filtered.shape[1],))\n",
    "text_input = Input(shape=(text_features_filtered.shape[1],))\n",
    "\n",
    "# CNN images\n",
    "x_img = Conv2D(32, (3, 3), activation='relu')(img_input)\n",
    "x_img = MaxPooling2D()(x_img)\n",
    "x_img = Conv2D(64, (3, 3), activation='relu')(x_img)\n",
    "x_img = GlobalAveragePooling2D()(x_img)\n",
    "x_img = Dense(64, activation='relu')(x_img)\n",
    "\n",
    "# MLP metadata + texte\n",
    "x_meta = Dense(64, activation='relu')(meta_input)\n",
    "x_text = Dense(64, activation='relu')(text_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Lambda, Concatenate, GlobalAveragePooling1D, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# Ajouter une dimension temporelle √† chaque modalit√©\n",
    "x_img_seq = Lambda(lambda x: tf.expand_dims(x, axis=1))(x_img)\n",
    "x_meta_seq = Lambda(lambda x: tf.expand_dims(x, axis=1))(x_meta)\n",
    "x_text_seq = Lambda(lambda x: tf.expand_dims(x, axis=1))(x_text)\n",
    "\n",
    "# Fusion multimodale : (batch, 3, 64)\n",
    "fused = Concatenate(axis=1)([x_img_seq, x_meta_seq, x_text_seq])\n",
    "\n",
    "# Transformer\n",
    "fused = TransformerBlock(embed_dim=64, num_heads=4, ff_dim=128)(fused)\n",
    "\n",
    "# Agr√©gation temporelle\n",
    "fused = GlobalAveragePooling1D()(fused)\n",
    "\n",
    "# Classification finale\n",
    "x = Dense(128, activation='relu')(fused)\n",
    "output = Dense(len(label_names), activation='softmax')(x)\n",
    "\n",
    "# Mod√®le\n",
    "model = Model(inputs=[img_input, meta_input, text_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üöÇ Entra√Ænement\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    [X_img_train, X_meta_train, X_txt_train], y_train,\n",
    "    validation_data=([X_img_val, X_meta_val, X_txt_val], y_val),\n",
    "    epochs=10,\n",
    "    batch_size=16,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=[early_stop]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Evaluation test\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Pr√©dictions\n",
    "y_pred_proba = model.predict([X_img_test, X_meta_test, X_txt_test])\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Rapport de classification\n",
    "print(classification_report(y_true, y_pred, target_names=label_names))\n",
    "print(\"F1-score (weighted):\", f1_score(y_true, y_pred, average='weighted'))\n",
    "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "\n",
    "# üìå Matrice de confusion\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_names, yticklabels=label_names)\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# üìà Courbes de loss et accuracy\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='train loss')\n",
    "    if 'val_loss' in history.history:\n",
    "        plt.plot(history.history['val_loss'], label='val loss')\n",
    "    plt.title('Loss during training')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='train accuracy')\n",
    "    if 'val_accuracy' in history.history:\n",
    "        plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
    "    plt.title('Accuracy during training')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Appelle la fonction avec l'objet history renvoy√© par model.fit()\n",
    "plot_training_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# AUC\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "y_test_bin = label_binarize(y_true, classes=range(len(label_names)))\n",
    "y_pred_bin = y_pred_proba\n",
    "auc_score = roc_auc_score(y_test_bin, y_pred_bin, average='macro', multi_class='ovr')\n",
    "print(\"ROC AUC (macro, one-vs-rest):\", auc_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
